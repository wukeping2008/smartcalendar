'use client'

import React, { useState, useEffect, useRef } from 'react'
import { Button } from '../../src/components/ui/button'
import { useEventStore } from '../../lib/stores/event-store'
import { EventCategory, Priority, EventStatus, EnergyLevel } from '../../types/event'
import { AzureSpeechService } from '../../lib/services/AzureSpeechService'
import { aiService } from '../../lib/services/AIService'
import type { IAudioService } from '../../lib/services/IAudioService'
import { useVoiceCommandStore, VoiceCommandIntent } from '../../lib/stores/voice-command-store'
import { PanelType } from '../../types/floating-panel'

// Type definitions for Web Speech API to fix TypeScript errors
interface SpeechRecognition extends EventTarget {
  grammars: SpeechGrammarList;
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  maxAlternatives: number;
  serviceURI: string;
  start(): void;
  stop(): void;
  abort(): void;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  // Add other event handlers as needed: onaudiostart, onsoundstart, onspeechstart, onspeechend, onsoundend, onaudiostart
}

interface SpeechRecognitionEvent extends Event {
  readonly resultIndex: number;
  readonly results: SpeechRecognitionResultList;
}

interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionResult {
  readonly isFinal: boolean;
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  readonly transcript: string;
  readonly confidence: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  readonly error: string;
  readonly message: string;
}

interface SpeechGrammarList {
  addFromString(string: string, weight?: number): void;
  // Add other properties and methods as needed
}

// Extend window object
interface ExtendedWindow extends Window {
  webkitSpeechRecognition?: any;
  SpeechRecognition?: any;
}

declare const window: ExtendedWindow;

interface VoiceInputButtonProps {
  onResult?: (text: string) => void
  className?: string
}

export default function VoiceInputButton({ onResult, className = "" }: VoiceInputButtonProps) {
  const [isListening, setIsListening] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [currentText, setCurrentText] = useState('')
  const [isInitialized, setIsInitialized] = useState(false)
  const { addEvent } = useEventStore()
  
  const audioServiceRef = useRef<IAudioService | null>(null)
  const accumulatedTextRef = useRef('')
  const [voiceInteractions, setVoiceInteractions] = useState<Array<{
    id: string
    timestamp: Date
    input: string
    result: string
    success: boolean
  }>>([])

  // æ·»åŠ è¯­éŸ³äº¤äº’è®°å½•
  const addVoiceInteraction = (input: string, result: string, success: boolean) => {
    const interaction = {
      id: `voice_${Date.now()}`,
      timestamp: new Date(),
      input,
      result,
      success
    }
    setVoiceInteractions(prev => [interaction, ...prev.slice(0, 9)]) // ä¿ç•™æœ€è¿‘10æ¡è®°å½•
    
    // ä¿å­˜åˆ°localStorage
    if (typeof window !== 'undefined') {
      try {
        const saved = localStorage.getItem('voice_interactions') || '[]'
        const interactions = JSON.parse(saved)
        interactions.unshift(interaction)
        localStorage.setItem('voice_interactions', JSON.stringify(interactions.slice(0, 50))) // ä¿ç•™æœ€è¿‘50æ¡
      } catch (error) {
        console.warn('ä¿å­˜è¯­éŸ³äº¤äº’è®°å½•å¤±è´¥:', error)
      }
    }
  }

  // åŠ è½½å†å²è®°å½•
  useEffect(() => {
    if (typeof window !== 'undefined') {
      try {
        const saved = localStorage.getItem('voice_interactions')
        if (saved) {
          const interactions = JSON.parse(saved).slice(0, 10)
          setVoiceInteractions(interactions.map((item: { timestamp: string | number | Date }) => ({
            ...item,
            timestamp: new Date(item.timestamp)
          })))
        }
      } catch (error) {
        console.warn('åŠ è½½è¯­éŸ³äº¤äº’è®°å½•å¤±è´¥:', error)
      }
    }
  }, [])

  // åˆå§‹åŒ–è¯­éŸ³æœåŠ¡
  useEffect(() => {
    const initAudioService = async () => {
      try {
        // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒè¯­éŸ³è¯†åˆ«
        const speechRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window
        
        if (!speechRecognition) {
          setIsSupported(false)
          return
        }

        // å°è¯•åˆå§‹åŒ–Azureè¯­éŸ³æœåŠ¡
        try {
          const hasAzureConfig = process.env.NEXT_PUBLIC_AZURE_SPEECH_KEY && 
                                 process.env.NEXT_PUBLIC_AZURE_SPEECH_REGION
          
          if (hasAzureConfig) {
            audioServiceRef.current = new AzureSpeechService()
            if (!audioServiceRef.current) return;
            await audioServiceRef.current.initTranscription()
            await audioServiceRef.current.initSynthesis()
            
            // è®¾ç½®å›è°ƒ
            audioServiceRef.current.onTranscriptionUpdate((text: string, isFinal: boolean) => {
              if (isFinal && text.trim()) {
                accumulatedTextRef.current += text + ' '
                setCurrentText(accumulatedTextRef.current)
                setTranscript(accumulatedTextRef.current.trim())
              } else {
                setCurrentText((accumulatedTextRef.current + text).trim())
              }
            })

            audioServiceRef.current.onError((error) => {
              console.warn('Azureè¯­éŸ³æœåŠ¡é”™è¯¯:', error)
              setIsListening(false)
            })

            setIsSupported(true)
            setIsInitialized(true)
            return
          }
        } catch (azureError) {
          console.warn('Azureè¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°æµè§ˆå™¨API:', azureError)
        }

        // å›é€€åˆ°æµè§ˆå™¨è¯­éŸ³è¯†åˆ«
        setIsSupported(speechRecognition)
        setIsInitialized(false)
        
      } catch (error) {
        console.warn('è¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error)
        setIsSupported(false)
      }
    }

    initAudioService()

    // æ¸…ç†å‡½æ•°
    return () => {
      if (audioServiceRef.current) {
        try {
          audioServiceRef.current.destroy()
        } catch (error) {
          console.warn('æ¸…ç†è¯­éŸ³æœåŠ¡å¤±è´¥:', error)
        }
      }
    }
  }, [])

  // è¯­éŸ³è¯†åˆ«
  const startListening = async () => {
    if (!isSupported) {
      speakResponse('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨Chromeæµè§ˆå™¨')
      return
    }

    try {
      // æ¸…ç©ºä¹‹å‰çš„ç»“æœ
      setTranscript('')
      setCurrentText('')
      accumulatedTextRef.current = ''

      // å¦‚æœæœ‰AzureæœåŠ¡ï¼Œä½¿ç”¨Azure
      if (audioServiceRef.current && isInitialized) {
        setIsListening(true)
        await audioServiceRef.current.startTranscription()
        return
      }

      // å›é€€åˆ°æµè§ˆå™¨API
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition
      
      if (!SpeechRecognition) {
        speakResponse('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½')
        return
      }

      const recognition = new SpeechRecognition()

      recognition.continuous = true  // æ”¹ä¸ºè¿ç»­è¯†åˆ«
      recognition.interimResults = true  // æ˜¾ç¤ºä¸­é—´ç»“æœ
      recognition.lang = 'zh-CN'
      recognition.maxAlternatives = 1

      recognition.onstart = () => {
        setIsListening(true)
        speakResponse('å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯')
      }

      recognition.onresult = (event: SpeechRecognitionEvent) => {
        let interimTranscript = ''
        let finalTranscript = ''

        for (let i = event.resultIndex; i < event.results.length; ++i) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript + ' ';
          } else {
            interimTranscript += event.results[i][0].transcript;
          }
        }

        // æ›´æ–°æ˜¾ç¤º
        if (finalTranscript) {
          setTranscript(finalTranscript.trim())
          setCurrentText(finalTranscript.trim())
          onResult?.(finalTranscript.trim())
        } else {
          setCurrentText(interimTranscript)
        }
      }

      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        console.warn('è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error)
        setIsListening(false)
        if (event.error === 'no-speech') {
          speakResponse('æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•')
        } else if (event.error === 'not-allowed') {
          speakResponse('è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£æƒé™')
        } else {
          speakResponse('è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•')
        }
      }

      recognition.onend = () => {
        setIsListening(false)
        // å¦‚æœæœ‰æœ€ç»ˆè¯†åˆ«ç»“æœï¼Œå¤„ç†å®ƒ
        const finalText = transcript || currentText
        if (finalText.trim()) {
          handleVoiceResult(finalText.trim())
        } else {
          speakResponse('æ²¡æœ‰è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹')
        }
      }

      recognition.start()
      
    } catch (error) {
      console.error('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error)
      setIsListening(false)
      speakResponse('è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥ï¼Œè¯·é‡è¯•')
    }
  }

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  const stopListening = async () => {
    try {
      if (audioServiceRef.current && isInitialized) {
        await audioServiceRef.current.stopTranscription()
        
        // å¤„ç†Azureè¯†åˆ«ç»“æœ
        if (currentText.trim()) {
          handleVoiceResult(currentText.trim())
        }
      }
      setIsListening(false)
    } catch (error) {
      // åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥ - é™é»˜å¤„ç†
      setIsListening(false)
    }
  }

  // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ
  const handleVoiceResult = async (result: string) => {
    onResult?.(result);

    // 1. å°è¯•è§£æä¸ºé¢æ¿æ§åˆ¶å‘½ä»¤
    const panelCommand = await aiService.parsePanelCommand(result);
    if (panelCommand.intent === 'open_panel' || panelCommand.intent === 'close_panel') {
      const { setCommand } = useVoiceCommandStore.getState();
      setCommand({
        intent: panelCommand.intent as VoiceCommandIntent,
        panelType: panelCommand.panelType as PanelType,
      });
      speakResponse(`å¥½çš„ï¼Œæ­£åœ¨${panelCommand.intent === 'open_panel' ? 'æ‰“å¼€' : 'å…³é—­'}${panelCommand.panelType}é¢æ¿`);
      return;
    }

    // 2. å¦‚æœä¸æ˜¯é¢æ¿å‘½ä»¤ï¼Œåˆ™å°è¯•è§£æä¸ºäº‹ä»¶åˆ›å»ºå‘½ä»¤
    try {
      const parsedEventCommand = await aiService.parseNaturalLanguageCommand(result);
      const entities = parsedEventCommand.entities || {};

      if (parsedEventCommand.intent === 'create_event' && entities.title) {
        const eventData = {
          title: entities.title,
          description: `é€šè¿‡è¯­éŸ³åˆ›å»ºï¼š${result}`,
          startTime: entities.dateTime ? new Date(entities.dateTime) : new Date(Date.now() + 60 * 60 * 1000),
          endTime: entities.dateTime && entities.duration 
            ? new Date(new Date(entities.dateTime).getTime() + entities.duration * 60000) 
            : new Date(Date.now() + 2 * 60 * 60 * 1000),
          category: entities.category || EventCategory.OTHER,
          priority: entities.priority || Priority.MEDIUM,
          status: EventStatus.PLANNED,
          position: { x: 0, y: 0, z: 0 },
          size: { width: 200, height: 80, depth: 20 },
          color: getCategoryColor(entities.category || EventCategory.OTHER),
          opacity: 0.8,
          isSelected: false,
          isDragging: false,
          isHovered: false,
          isConflicted: false,
          tags: ['è¯­éŸ³åˆ›å»º'],
          reminders: [],
          energyRequired: EnergyLevel.MEDIUM,
          estimatedDuration: entities.duration || 60,
          isMarketProtected: false,
          flexibilityScore: 70
        };
        
        addEvent(eventData);
        const successMessage = `å·²åˆ›å»ºäº‹ä»¶ï¼š${eventData.title}ï¼Œæ—¶é—´ï¼š${eventData.startTime.toLocaleString()}`;
        speakResponse(successMessage);
        addVoiceInteraction(result, successMessage, true);
      } else {
        // å¦‚æœAIè§£æå¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°è§£æ
        const eventData = parseVoiceToEvent(result)
        if (eventData) {
          try {
            addEvent(eventData)
            const successMessage = `å·²åˆ›å»ºäº‹ä»¶ï¼š${eventData.title}ï¼Œæ—¶é—´ï¼š${eventData.startTime.toLocaleString()}`
            speakResponse(successMessage)
            addVoiceInteraction(result, successMessage, true)
          } catch (error) {
            const errorMessage = 'åˆ›å»ºäº‹ä»¶å¤±è´¥ï¼Œè¯·é‡è¯•'
            speakResponse(errorMessage)
            addVoiceInteraction(result, errorMessage, false)
          }
        } else {
          const errorMessage = 'æŠ±æ­‰ï¼Œæ— æ³•ç†è§£æ‚¨çš„æŒ‡ä»¤ã€‚è¯·å°è¯•è¯´ï¼šåˆ›å»ºä¼šè®®ã€æ˜å¤©9ç‚¹å¼€ä¼šã€æ·»åŠ è¿åŠ¨æ—¶é—´ç­‰'
          speakResponse(errorMessage)
          addVoiceInteraction(result, errorMessage, false)
        }
      }
    } catch (error) {
      // AIæœåŠ¡å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°è§£æ
      const eventData = parseVoiceToEvent(result)
      if (eventData) {
        try {
          addEvent(eventData)
          const successMessage = `å·²åˆ›å»ºäº‹ä»¶ï¼š${eventData.title}ï¼Œæ—¶é—´ï¼š${eventData.startTime.toLocaleString()}`
          speakResponse(successMessage)
          addVoiceInteraction(result, successMessage, true)
        } catch (error) {
          const errorMessage = 'åˆ›å»ºäº‹ä»¶å¤±è´¥ï¼Œè¯·é‡è¯•'
          speakResponse(errorMessage)
          addVoiceInteraction(result, errorMessage, false)
        }
      } else {
        const errorMessage = 'æŠ±æ­‰ï¼Œæ— æ³•ç†è§£æ‚¨çš„æŒ‡ä»¤ã€‚è¯·å°è¯•è¯´ï¼šåˆ›å»ºä¼šè®®ã€æ˜å¤©9ç‚¹å¼€ä¼šã€æ·»åŠ è¿åŠ¨æ—¶é—´ç­‰'
        speakResponse(errorMessage)
        addVoiceInteraction(result, errorMessage, false)
      }
    }
  }

  // è¯­éŸ³åˆæˆå“åº”
  const speakResponse = async (text: string) => {
    try {
      // ä¼˜å…ˆä½¿ç”¨Azureè¯­éŸ³åˆæˆ
      if (audioServiceRef.current && isInitialized) {
        await audioServiceRef.current.synthesizeAndPlay(text)
        return
      }
      
      // å›é€€åˆ°æµè§ˆå™¨è¯­éŸ³åˆæˆ
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = 'zh-CN'
        window.speechSynthesis.speak(utterance)
      }
    } catch (error) {
      // è¯­éŸ³åˆæˆå¤±è´¥ï¼Œå›é€€åˆ°æµè§ˆå™¨API
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = 'zh-CN'
        window.speechSynthesis.speak(utterance)
      }
    }
  }

  // è¯­éŸ³åˆæˆï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
  const speak = (text: string) => {
    speakResponse(text)
  }

  // è§£æè¯­éŸ³æŒ‡ä»¤åˆ›å»ºäº‹ä»¶
  const parseVoiceToEvent = (text: string) => {
    const normalizedText = text.toLowerCase().trim()
    
    // æ›´çµæ´»çš„æŒ‡ä»¤è¯†åˆ«
    const hasCreateCommand = normalizedText.includes('åˆ›å»º') || 
                           normalizedText.includes('æ–°å»º') || 
                           normalizedText.includes('æ·»åŠ ') ||
                           normalizedText.includes('å®‰æ’') ||
                           normalizedText.includes('é¢„çº¦') ||
                           normalizedText.includes('æé†’æˆ‘') ||
                           // ç›´æ¥çš„æ—¶é—´è¡¨è¾¾ä¹Ÿåº”è¯¥è¢«è¯†åˆ«
                           /\d{1,2}[ç‚¹æ—¶]/.test(normalizedText) ||
                           /(ä»Šå¤©|æ˜å¤©|åå¤©|ä¸‹å‘¨)/.test(normalizedText)
    
    if (!hasCreateCommand && 
        !normalizedText.includes('ä¼šè®®') && 
        !normalizedText.includes('å·¥ä½œ') && 
        !normalizedText.includes('è¿åŠ¨') && 
        !normalizedText.includes('åƒé¥­') &&
        !normalizedText.includes('ä¼‘æ¯')) {
      return null
    }

    let title = ''
    let category = EventCategory.OTHER
    let priority = Priority.MEDIUM
    const now = new Date()
    let startTime = new Date(now.getTime() + 60 * 60 * 1000) // é»˜è®¤1å°æ—¶å
    let endTime = new Date(startTime.getTime() + 60 * 60 * 1000) // é»˜è®¤æŒç»­1å°æ—¶

    // ç±»åˆ«è¯†åˆ«
    if (normalizedText.includes('ä¼šè®®') || normalizedText.includes('å¼€ä¼š')) {
      category = EventCategory.MEETING
      title = 'ä¼šè®®'
    } else if (normalizedText.includes('å·¥ä½œ') || normalizedText.includes('é¡¹ç›®')) {
      category = EventCategory.WORK
      title = 'å·¥ä½œä»»åŠ¡'
    } else if (normalizedText.includes('è¿åŠ¨') || normalizedText.includes('é”»ç‚¼')) {
      category = EventCategory.EXERCISE
      title = 'è¿åŠ¨æ—¶é—´'
    } else if (normalizedText.includes('åƒé¥­') || normalizedText.includes('åˆé¤') || normalizedText.includes('æ™šé¤')) {
      category = EventCategory.MEAL
      title = 'ç”¨é¤æ—¶é—´'
    } else if (normalizedText.includes('ä¼‘æ¯')) {
      category = EventCategory.BREAK
      title = 'ä¼‘æ¯æ—¶é—´'
    }

    // ä¼˜å…ˆçº§è¯†åˆ«
    if (normalizedText.includes('ç´§æ€¥') || normalizedText.includes('é‡è¦')) {
      priority = Priority.URGENT
    } else if (normalizedText.includes('é«˜ä¼˜å…ˆçº§')) {
      priority = Priority.HIGH
    }

    // æ—¶é—´è§£æ
    const timeMatch = normalizedText.match(/(\d{1,2})[ç‚¹æ—¶](\d{1,2}[åˆ†]?)?/)
    const dateMatch = normalizedText.match(/(ä»Šå¤©|æ˜å¤©|åå¤©|ä¸‹å‘¨)/)
    
    const targetDate = new Date(now)
    
    // å¤„ç†æ—¥æœŸ
    if (dateMatch) {
      const dateStr = dateMatch[1]
      if (dateStr === 'æ˜å¤©') {
        targetDate.setDate(targetDate.getDate() + 1)
      } else if (dateStr === 'åå¤©') {
        targetDate.setDate(targetDate.getDate() + 2)
      } else if (dateStr === 'ä¸‹å‘¨') {
        targetDate.setDate(targetDate.getDate() + 7)
      }
    }
    
    // å¤„ç†æ—¶é—´
    if (timeMatch) {
      const hour = parseInt(timeMatch[1])
      const minute = timeMatch[2] ? parseInt(timeMatch[2].replace('åˆ†', '')) : 0
      
      if (hour >= 0 && hour <= 23 && minute >= 0 && minute < 60) {
        startTime = new Date(targetDate.getFullYear(), targetDate.getMonth(), targetDate.getDate(), hour, minute)
        endTime = new Date(startTime.getTime() + 60 * 60 * 1000)
      }
    } else {
      // å¦‚æœæ²¡æœ‰å…·ä½“æ—¶é—´ï¼Œæ ¹æ®å½“å‰æ—¶é—´æ™ºèƒ½æ¨æ–­
      if (targetDate.getDate() === now.getDate()) {
        // ä»Šå¤©çš„è¯ï¼Œè®¾ç½®ä¸º1å°æ—¶å
        startTime = new Date(now.getTime() + 60 * 60 * 1000)
        endTime = new Date(startTime.getTime() + 60 * 60 * 1000)
      } else {
        // å…¶ä»–æ—¥æœŸï¼Œè®¾ç½®ä¸ºä¸Šåˆ9ç‚¹
        startTime = new Date(targetDate.getFullYear(), targetDate.getMonth(), targetDate.getDate(), 9, 0)
        endTime = new Date(startTime.getTime() + 60 * 60 * 1000)
      }
    }

    // æå–æ ‡é¢˜
    if (!title) {
      title = normalizedText
        .replace(/åˆ›å»º|æ–°å»º|æ·»åŠ |å®‰æ’|é¢„çº¦|æé†’æˆ‘/g, '')
        .replace(/\d{1,2}[ç‚¹æ—¶](\d{1,2}[åˆ†]?)?/g, '')
        .replace(/ä»Šå¤©|æ˜å¤©|åå¤©|ä¸‹å‘¨|ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š/g, '')
        .replace(/ç´§æ€¥|é‡è¦|é«˜ä¼˜å…ˆçº§|ä½ä¼˜å…ˆçº§/g, '')
        .replace(/çš„?äº‹ä»¶?$/, '') // å»æ‰ç»“å°¾çš„"äº‹ä»¶"
        .trim()
      
      if (!title || title.length < 2) {
        // æ ¹æ®ç±»åˆ«è®¾ç½®é»˜è®¤æ ‡é¢˜
        if (category === EventCategory.MEETING) {
          title = 'ä¼šè®®'
        } else if (category === EventCategory.WORK) {
          title = 'å·¥ä½œä»»åŠ¡'
        } else if (category === EventCategory.EXERCISE) {
          title = 'è¿åŠ¨æ—¶é—´'
        } else if (category === EventCategory.MEAL) {
          title = 'ç”¨é¤æ—¶é—´'
        } else if (category === EventCategory.BREAK) {
          title = 'ä¼‘æ¯æ—¶é—´'
        } else {
          title = 'æ–°äº‹ä»¶'
        }
      }
    }

    return {
      title,
      description: `é€šè¿‡è¯­éŸ³åˆ›å»ºï¼š${text}`,
      startTime,
      endTime,
      category,
      priority,
      status: EventStatus.PLANNED,
      position: { x: 0, y: 0, z: 0 },
      size: { width: 200, height: 80, depth: 20 },
      color: getCategoryColor(category),
      opacity: 0.8,
      isSelected: false,
      isDragging: false,
      isHovered: false,
      isConflicted: false,
      tags: ['è¯­éŸ³åˆ›å»º'],
      reminders: [],
      energyRequired: EnergyLevel.MEDIUM,
      estimatedDuration: 60,
      isMarketProtected: false,
      flexibilityScore: 70
    }
  }

  // è·å–ç±»åˆ«é¢œè‰²
  const getCategoryColor = (category: EventCategory): string => {
    const colors = {
      [EventCategory.WORK]: '#3b82f6',
      [EventCategory.PERSONAL]: '#10b981',
      [EventCategory.MEETING]: '#f59e0b',
      [EventCategory.BREAK]: '#8b5cf6',
      [EventCategory.EXERCISE]: '#ef4444',
      [EventCategory.MEAL]: '#f97316',
      [EventCategory.TRAVEL]: '#06b6d4',
      [EventCategory.OTHER]: '#6b7280',
      // Tradingä¸“ä¸šç±»åˆ«é¢œè‰²
      [EventCategory.TRADING]: '#dc2626',        // çº¢è‰² - äº¤æ˜“ç›¸å…³
      [EventCategory.LIFE_ROUTINE]: '#059669',   // ç»¿è‰² - ç”Ÿæ´»ä¾‹ç¨‹
      [EventCategory.PREPARATION]: '#7c3aed'     // ç´«è‰² - å‡†å¤‡å·¥ä½œ
    }
    return colors[category]
  }

  if (!isSupported) {
    return (
      <Button 
        variant="outline" 
        className="w-full text-gray-400 border-gray-600 cursor-not-allowed" 
        size="sm"
        disabled
      >
        ğŸ¤ è¯­éŸ³ä¸æ”¯æŒ
      </Button>
    )
  }

  return (
    <div className={className}>
      <Button 
        onClick={isListening ? stopListening : startListening}
        variant="outline" 
        className={`w-full border-white/20 ${
          isListening 
            ? 'bg-red-600 text-white animate-pulse' 
            : 'text-white hover:bg-white/10'
        }`}
        size="sm"
      >
        {isListening ? 'ğŸ”´ ç‚¹å‡»åœæ­¢å½•éŸ³' : 'ğŸ¤ è¯­éŸ³åˆ›å»º'}
      </Button>
      
      {(transcript || currentText) && (
        <div className="mt-2 text-xs text-gray-400 p-2 bg-black/20 rounded">
          è¯†åˆ«ç»“æœ: {transcript || currentText}
        </div>
      )}
      
      {isInitialized && (
        <div className="mt-1 text-xs text-green-400">
          âœ… Azureè¯­éŸ³æœåŠ¡å·²å°±ç»ª
        </div>
      )}

      {/* è¯­éŸ³äº¤äº’è®°å½• */}
      {voiceInteractions.length > 0 && (
        <div className="mt-2 text-xs">
          <div className="text-gray-300 mb-1">æœ€è¿‘è¯­éŸ³äº¤äº’:</div>
          <div className="space-y-1 max-h-32 overflow-y-auto bg-black/10 rounded p-2">
            {voiceInteractions.slice(0, 3).map((interaction) => (
              <div key={interaction.id} className={`text-xs p-1 rounded ${
                interaction.success ? 'bg-green-900/30 border-l-2 border-green-500' : 'bg-red-900/30 border-l-2 border-red-500'
              }`}>
                <div className="font-mono text-gray-300">
                  {interaction.input}
                </div>
                <div className={interaction.success ? 'text-green-400' : 'text-red-400'}>
                  {interaction.result}
                </div>
                <div className="text-xs text-gray-500 mt-1">
                  {interaction.timestamp.toLocaleTimeString()}
                </div>
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  )
}
