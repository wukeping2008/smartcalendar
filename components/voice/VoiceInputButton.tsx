'use client'

import React, { useState, useEffect, useRef } from 'react'
import { Button } from '@/components/ui/button'
import { useEventStore } from '../../lib/stores/event-store'
import { EventCategory, Priority, EventStatus, EnergyLevel } from '../../types/event'
import { AzureSpeechService } from '../../lib/services/AzureSpeechService'
import type { IAudioService } from '../../lib/services/IAudioService'

// æ‰©å±•æµè§ˆå™¨ç±»å‹å®šä¹‰
interface ExtendedWindow extends Window {
  webkitSpeechRecognition?: typeof SpeechRecognition
  SpeechRecognition?: typeof SpeechRecognition
}

// è¯­éŸ³è¯†åˆ«äº‹ä»¶ç±»å‹
interface SpeechRecognitionEvent {
  results: {
    [index: number]: {
      [index: number]: {
        transcript: string
        confidence: number
      }
    }
  }
}

interface SpeechRecognitionErrorEvent {
  error: string
  message: string
}

declare const window: ExtendedWindow

interface VoiceInputButtonProps {
  onResult?: (text: string) => void
  className?: string
}

export default function VoiceInputButton({ onResult, className = "" }: VoiceInputButtonProps) {
  const [isListening, setIsListening] = useState(false)
  const [isSupported, setIsSupported] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [currentText, setCurrentText] = useState('')
  const [isInitialized, setIsInitialized] = useState(false)
  const { addEvent } = useEventStore()
  
  const audioServiceRef = useRef<IAudioService | null>(null)
  const accumulatedTextRef = useRef('')

  // åˆå§‹åŒ–Azure Speech Service
  useEffect(() => {
    const initAudioService = async () => {
      try {
        // ä¼˜å…ˆä½¿ç”¨Azure Speech Serviceï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™å›é€€åˆ°æµè§ˆå™¨API
        const hasAzureConfig = process.env.NEXT_PUBLIC_AZURE_SPEECH_KEY && 
                               process.env.NEXT_PUBLIC_AZURE_SPEECH_REGION
        
        if (hasAzureConfig) {
          audioServiceRef.current = new AzureSpeechService()
        } else {
          // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
          const speechRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window
          setIsSupported(speechRecognition)
          return
        }

        // åˆå§‹åŒ–AzureæœåŠ¡
        await audioServiceRef.current.initTranscription()
        await audioServiceRef.current.initSynthesis()
        
        // è®¾ç½®å›è°ƒ
        audioServiceRef.current.onTranscriptionUpdate((text: string, isFinal: boolean) => {
          if (isFinal && text) {
            accumulatedTextRef.current += text + ' '
            setCurrentText(accumulatedTextRef.current)
            setTranscript(accumulatedTextRef.current)
          } else {
            setCurrentText(accumulatedTextRef.current + text)
          }
        })

        audioServiceRef.current.onError((error) => {
          // Azureè¯­éŸ³æœåŠ¡é”™è¯¯ - é™é»˜å¤„ç†
          setIsListening(false)
        })

        setIsSupported(true)
        setIsInitialized(true)
      } catch (error) {
        // åˆå§‹åŒ–è¯­éŸ³æœåŠ¡å¤±è´¥ï¼Œå›é€€åˆ°æµè§ˆå™¨API
        const speechRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window
        setIsSupported(speechRecognition)
      }
    }

    initAudioService()

    // æ¸…ç†å‡½æ•°
    return () => {
      if (audioServiceRef.current) {
        audioServiceRef.current.destroy()
      }
    }
  }, [])

  // è¯­éŸ³è¯†åˆ«
  const startListening = async () => {
    if (!isSupported) {
      alert('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«')
      return
    }

    try {
      // å¦‚æœæœ‰AzureæœåŠ¡ï¼Œä½¿ç”¨Azure
      if (audioServiceRef.current && isInitialized) {
        setIsListening(true)
        setTranscript('')
        accumulatedTextRef.current = ''
        
        await audioServiceRef.current.startTranscription()
        return
      }

      // å›é€€åˆ°æµè§ˆå™¨API
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition
      
      if (!SpeechRecognition) {
        alert('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«')
        return
      }
      const recognition = new SpeechRecognition()

      recognition.continuous = false
      recognition.interimResults = false
      recognition.lang = 'zh-CN'

      recognition.onstart = () => {
        setIsListening(true)
        setTranscript('')
      }

      recognition.onresult = (event: SpeechRecognitionEvent) => {
        const result = event.results[0][0].transcript
        setTranscript(result)
        onResult?.(result)
        
        // è‡ªåŠ¨è§£æå¹¶åˆ›å»ºäº‹ä»¶
        handleVoiceResult(result)
      }

      recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
        // è¯­éŸ³è¯†åˆ«é”™è¯¯ - é™é»˜å¤„ç†
        setIsListening(false)
      }

      recognition.onend = () => {
        setIsListening(false)
      }

      recognition.start()
    } catch (error) {
      // å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥ - é™é»˜å¤„ç†
      setIsListening(false)
    }
  }

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  const stopListening = async () => {
    try {
      if (audioServiceRef.current && isInitialized) {
        await audioServiceRef.current.stopTranscription()
        
        // å¤„ç†Azureè¯†åˆ«ç»“æœ
        if (currentText.trim()) {
          handleVoiceResult(currentText.trim())
        }
      }
      setIsListening(false)
    } catch (error) {
      // åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥ - é™é»˜å¤„ç†
      setIsListening(false)
    }
  }

  // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ
  const handleVoiceResult = (result: string) => {
    onResult?.(result)
    
    // è‡ªåŠ¨è§£æå¹¶åˆ›å»ºäº‹ä»¶
    const eventData = parseVoiceToEvent(result)
    if (eventData) {
      addEvent(eventData)
      speakResponse(`å·²åˆ›å»ºäº‹ä»¶ï¼š${eventData.title}`)
    } else {
      speakResponse('æŠ±æ­‰ï¼Œæ— æ³•ç†è§£æ‚¨çš„æŒ‡ä»¤ï¼Œè¯·é‡è¯•')
    }
  }

  // è¯­éŸ³åˆæˆå“åº”
  const speakResponse = async (text: string) => {
    try {
      // ä¼˜å…ˆä½¿ç”¨Azureè¯­éŸ³åˆæˆ
      if (audioServiceRef.current && isInitialized) {
        await audioServiceRef.current.synthesizeAndPlay(text)
        return
      }
      
      // å›é€€åˆ°æµè§ˆå™¨è¯­éŸ³åˆæˆ
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = 'zh-CN'
        window.speechSynthesis.speak(utterance)
      }
    } catch (error) {
      // è¯­éŸ³åˆæˆå¤±è´¥ï¼Œå›é€€åˆ°æµè§ˆå™¨API
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text)
        utterance.lang = 'zh-CN'
        window.speechSynthesis.speak(utterance)
      }
    }
  }

  // è¯­éŸ³åˆæˆï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
  const speak = (text: string) => {
    speakResponse(text)
  }

  // è§£æè¯­éŸ³æŒ‡ä»¤åˆ›å»ºäº‹ä»¶
  const parseVoiceToEvent = (text: string) => {
    const normalizedText = text.toLowerCase().trim()
    
    if (!normalizedText.includes('åˆ›å»º') && !normalizedText.includes('æ–°å»º') && !normalizedText.includes('æ·»åŠ ')) {
      return null
    }

    let title = ''
    let category = EventCategory.OTHER
    let priority = Priority.MEDIUM
    const now = new Date()
    let startTime = new Date(now.getTime() + 60 * 60 * 1000) // é»˜è®¤1å°æ—¶å
    let endTime = new Date(startTime.getTime() + 60 * 60 * 1000) // é»˜è®¤æŒç»­1å°æ—¶

    // ç±»åˆ«è¯†åˆ«
    if (normalizedText.includes('ä¼šè®®') || normalizedText.includes('å¼€ä¼š')) {
      category = EventCategory.MEETING
      title = 'ä¼šè®®'
    } else if (normalizedText.includes('å·¥ä½œ') || normalizedText.includes('é¡¹ç›®')) {
      category = EventCategory.WORK
      title = 'å·¥ä½œä»»åŠ¡'
    } else if (normalizedText.includes('è¿åŠ¨') || normalizedText.includes('é”»ç‚¼')) {
      category = EventCategory.EXERCISE
      title = 'è¿åŠ¨æ—¶é—´'
    } else if (normalizedText.includes('åƒé¥­') || normalizedText.includes('åˆé¤') || normalizedText.includes('æ™šé¤')) {
      category = EventCategory.MEAL
      title = 'ç”¨é¤æ—¶é—´'
    } else if (normalizedText.includes('ä¼‘æ¯')) {
      category = EventCategory.BREAK
      title = 'ä¼‘æ¯æ—¶é—´'
    }

    // ä¼˜å…ˆçº§è¯†åˆ«
    if (normalizedText.includes('ç´§æ€¥') || normalizedText.includes('é‡è¦')) {
      priority = Priority.URGENT
    } else if (normalizedText.includes('é«˜ä¼˜å…ˆçº§')) {
      priority = Priority.HIGH
    }

    // æ—¶é—´è§£æ
    const timeMatch = normalizedText.match(/(\d{1,2})[ç‚¹æ—¶]/)
    if (timeMatch) {
      const hour = parseInt(timeMatch[1])
      if (hour >= 0 && hour <= 23) {
        startTime = new Date(now.getFullYear(), now.getMonth(), now.getDate(), hour, 0)
        endTime = new Date(startTime.getTime() + 60 * 60 * 1000)
      }
    }

    // æå–æ ‡é¢˜
    if (!title) {
      title = normalizedText
        .replace(/åˆ›å»º|æ–°å»º|æ·»åŠ |å®‰æ’|é¢„çº¦/g, '')
        .replace(/\d{1,2}[ç‚¹æ—¶]\d{0,2}[åˆ†]?/g, '')
        .replace(/ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š|æ˜å¤©|åå¤©/g, '')
        .replace(/ç´§æ€¥|é‡è¦|é«˜ä¼˜å…ˆçº§|ä½ä¼˜å…ˆçº§/g, '')
        .trim()
      
      if (!title) {
        title = 'æ–°äº‹ä»¶'
      }
    }

    return {
      title,
      description: `é€šè¿‡è¯­éŸ³åˆ›å»ºï¼š${text}`,
      startTime,
      endTime,
      category,
      priority,
      status: EventStatus.PLANNED,
      position: { x: 0, y: 0, z: 0 },
      size: { width: 200, height: 80, depth: 20 },
      color: getCategoryColor(category),
      opacity: 0.8,
      isSelected: false,
      isDragging: false,
      isHovered: false,
      isConflicted: false,
      tags: ['è¯­éŸ³åˆ›å»º'],
      reminders: [],
      energyRequired: EnergyLevel.MEDIUM,
      estimatedDuration: 60,
      isMarketProtected: false,
      flexibilityScore: 70
    }
  }

  // è·å–ç±»åˆ«é¢œè‰²
  const getCategoryColor = (category: EventCategory): string => {
    const colors = {
      [EventCategory.WORK]: '#3b82f6',
      [EventCategory.PERSONAL]: '#10b981',
      [EventCategory.MEETING]: '#f59e0b',
      [EventCategory.BREAK]: '#8b5cf6',
      [EventCategory.EXERCISE]: '#ef4444',
      [EventCategory.MEAL]: '#f97316',
      [EventCategory.TRAVEL]: '#06b6d4',
      [EventCategory.OTHER]: '#6b7280',
      // Tradingä¸“ä¸šç±»åˆ«é¢œè‰²
      [EventCategory.TRADING]: '#dc2626',        // çº¢è‰² - äº¤æ˜“ç›¸å…³
      [EventCategory.LIFE_ROUTINE]: '#059669',   // ç»¿è‰² - ç”Ÿæ´»ä¾‹ç¨‹
      [EventCategory.PREPARATION]: '#7c3aed'     // ç´«è‰² - å‡†å¤‡å·¥ä½œ
    }
    return colors[category]
  }

  if (!isSupported) {
    return (
      <Button 
        variant="outline" 
        className="w-full text-gray-400 border-gray-600 cursor-not-allowed" 
        size="sm"
        disabled
      >
        ğŸ¤ è¯­éŸ³ä¸æ”¯æŒ
      </Button>
    )
  }

  return (
    <div className={className}>
      <Button 
        onClick={isListening ? stopListening : startListening}
        variant="outline" 
        className={`w-full border-white/20 ${
          isListening 
            ? 'bg-red-600 text-white animate-pulse' 
            : 'text-white hover:bg-white/10'
        }`}
        size="sm"
      >
        {isListening ? 'ğŸ”´ ç‚¹å‡»åœæ­¢å½•éŸ³' : 'ğŸ¤ è¯­éŸ³åˆ›å»º'}
      </Button>
      
      {(transcript || currentText) && (
        <div className="mt-2 text-xs text-gray-400 p-2 bg-black/20 rounded">
          è¯†åˆ«ç»“æœ: {transcript || currentText}
        </div>
      )}
      
      {isInitialized && (
        <div className="mt-1 text-xs text-green-400">
          âœ… Azureè¯­éŸ³æœåŠ¡å·²å°±ç»ª
        </div>
      )}
    </div>
  )
}
